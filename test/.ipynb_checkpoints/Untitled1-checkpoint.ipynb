{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "031e5154",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 准备数据集\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\tensorboard\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LooseVersion\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensorboard, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m LooseVersion(\n\u001b[0;32m      5\u001b[0m     tensorboard\u001b[38;5;241m.\u001b[39m__version__\n\u001b[0;32m      6\u001b[0m ) \u001b[38;5;241m<\u001b[39m LooseVersion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.15\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'"
     ]
    }
   ],
   "source": [
    "# 以 CIFAR10 数据集为例，展示一下完整的模型训练套路，完成对数据集的分类问题\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "# 准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(root=\"dataset\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root=\"dataset\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "# 获得数据集的长度 len(), 即length\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "\n",
    "# 格式化字符串, format() 中的数据会替换 {}\n",
    "print(\"训练数据集及的长度为: {}\".format(train_data_size))\n",
    "print(\"测试数据集及的长度为: {}\".format(test_data_size))\n",
    "\n",
    "# 利用DataLoader 来加载数据\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "class Model(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*4*4, 64),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.model(input)\n",
    "        return input\n",
    "\n",
    "model = Model()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()                        # 在 GPU 上进行训练\n",
    "\n",
    "# 创建损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "if torch.cuda.is_available():\n",
    "    loss_fn = loss_fn.cuda()                    # 在 GPU 上进行训练\n",
    "\n",
    "# 优化器\n",
    "learning_rate = 1e-2        # 1e-2 = 1 * (10)^(-2) = 1 / 100 = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# 设置训练网络的一些参数\n",
    "total_train_step = 0                        # 记录训练的次数\n",
    "total_test_step = 0                         # 记录测试的次数\n",
    "epoch = 10                                  # 训练的轮数\n",
    "\n",
    "# 添加tensorboard\n",
    "writer = SummaryWriter(\"logs_train\")\n",
    "start_time = time.time()                    # 开始训练的时间\n",
    "for i in range(epoch):\n",
    "    print(\"------第 {} 轮训练开始------\".format(i+1))\n",
    "\n",
    "    # 训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        if torch.cuda.is_available():\n",
    "            imgs = imgs.cuda()\n",
    "        targets = targets.cuda()            # 在gpu上训练\n",
    "        outputs = model(imgs)               # 将训练的数据放入\n",
    "        loss = loss_fn(outputs, targets)    # 得到损失值\n",
    "\n",
    "        optimizer.zero_grad()               # 优化过程中首先要使用优化器进行梯度清零\n",
    "        loss.backward()                     # 调用得到的损失，利用反向传播，得到每一个参数节点的梯度\n",
    "        optimizer.step()                    # 对参数进行优化\n",
    "        total_train_step += 1               # 上面就是进行了一次训练，训练次数 +1\n",
    "\n",
    "        # 只有训练步骤是100 倍数的时候才打印数据，可以减少一些没有用的数据，方便我们找到其他数据\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time = time.time()          # 训练结束时间\n",
    "            print(\"训练时间: {}\".format(end_time - start_time))\n",
    "            print(\"训练次数: {}, Loss: {}\".format(total_train_step, loss))\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
    "\n",
    "\n",
    "    # 如何知道模型有没有训练好，即有咩有达到自己想要的需求\n",
    "    # 我们可以在每次训练完一轮后，进行一次测试，在测试数据集上跑一遍，以测试数据集上的损失或正确率评估我们的模型有没有训练好\n",
    "\n",
    "    # 顾名思义，下面的代码没有梯度，即我们不会利用进行调优\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0                                      # 准确率\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:                        # 测试数据集中取数据\n",
    "            imgs, targets = data\n",
    "            if torch.cuda.is_available():\n",
    "                imgs = imgs.cuda()                          # 在 GPU 上进行训练\n",
    "                targets = targets.cuda()\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, targets)                # 这里的 loss 只是一部分数据(data) 在网络模型上的损失\n",
    "            total_test_loss = total_test_loss + loss        # 整个测试集的loss\n",
    "            accuracy = (outputs.argmax(1) == targets).sum() # 分类正确个数\n",
    "            total_accuracy += accuracy                      # 相加\n",
    "\n",
    "    print(\"整体测试集上的loss: {}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率: {}\".format(total_accuracy / test_data_size))\n",
    "    writer.add_scalar(\"test_loss\", total_test_loss)\n",
    "    writer.add_scalar(\"test_accuracy\", total_accuracy / test_data_size, total_test_step)\n",
    "    total_test_loss += 1                                    # 测试完了之后要 +1\n",
    "\n",
    "    torch.save(model, \"model_{}.pth\".format(i))\n",
    "    print(\"模型已保存\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以 CIFAR10 数据集为例，展示一下完整的模型训练套路，完成对数据集的分类问题\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "# 定义训练的设备\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# 准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(root=\"dataset\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root=\"dataset\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "# 获得数据集的长度 len(), 即length\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "\n",
    "# 格式化字符串, format() 中的数据会替换 {}\n",
    "print(\"训练数据集及的长度为: {}\".format(train_data_size))\n",
    "print(\"测试数据集及的长度为: {}\".format(test_data_size))\n",
    "\n",
    "# 利用DataLoader 来加载数据\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "class Model(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*4*4, 64),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.model(input)\n",
    "        return input\n",
    "\n",
    "model = Model()\n",
    "model = model.to(device)                    # 在 GPU 上进行训练\n",
    "\n",
    "# 创建损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)                # 在 GPU 上进行训练\n",
    "\n",
    "# 优化器\n",
    "learning_rate = 1e-2        # 1e-2 = 1 * (10)^(-2) = 1 / 100 = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# 设置训练网络的一些参数\n",
    "total_train_step = 0                        # 记录训练的次数\n",
    "total_test_step = 0                         # 记录测试的次数\n",
    "epoch = 10                                  # 训练的轮数\n",
    "\n",
    "# 添加tensorboard\n",
    "writer = SummaryWriter(\"logs_train\")\n",
    "start_time = time.time()                    # 开始训练的时间\n",
    "for i in range(epoch):\n",
    "    print(\"------第 {} 轮训练开始------\".format(i+1))\n",
    "\n",
    "    # 训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(imgs)               # 将训练的数据放入\n",
    "        loss = loss_fn(outputs, targets)    # 得到损失值\n",
    "\n",
    "        optimizer.zero_grad()               # 优化过程中首先要使用优化器进行梯度清零\n",
    "        loss.backward()                     # 调用得到的损失，利用反向传播，得到每一个参数节点的梯度\n",
    "        optimizer.step()                    # 对参数进行优化\n",
    "        total_train_step += 1               # 上面就是进行了一次训练，训练次数 +1\n",
    "\n",
    "        # 只有训练步骤是100 倍数的时候才打印数据，可以减少一些没有用的数据，方便我们找到其他数据\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time = time.time()          # 训练结束时间\n",
    "            print(\"训练时间: {}\".format(end_time - start_time))\n",
    "            print(\"训练次数: {}, Loss: {}\".format(total_train_step, loss))\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
    "\n",
    "\n",
    "    # 如何知道模型有没有训练好，即有咩有达到自己想要的需求\n",
    "    # 我们可以在每次训练完一轮后，进行一次测试，在测试数据集上跑一遍，以测试数据集上的损失或正确率评估我们的模型有没有训练好\n",
    "\n",
    "    # 顾名思义，下面的代码没有梯度，即我们不会利用进行调优\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0                                      # 准确率\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:                        # 测试数据集中取数据\n",
    "            imgs, targets = data\n",
    "            imgs = imgs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, targets)                # 这里的 loss 只是一部分数据(data) 在网络模型上的损失\n",
    "            total_test_loss = total_test_loss + loss        # 整个测试集的loss\n",
    "            accuracy = (outputs.argmax(1) == targets).sum() # 分类正确个数\n",
    "            total_accuracy += accuracy                      # 相加\n",
    "\n",
    "    print(\"整体测试集上的loss: {}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率: {}\".format(total_accuracy / test_data_size))\n",
    "    writer.add_scalar(\"test_loss\", total_test_loss)\n",
    "    writer.add_scalar(\"test_accuracy\", total_accuracy / test_data_size, total_test_step)\n",
    "    total_test_loss += 1                                    # 测试完了之后要 +1\n",
    "\n",
    "    torch.save(model, \"model_{}.pth\".format(i))\n",
    "    print(\"模型已保存\")\n",
    "\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
