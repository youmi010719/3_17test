{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58ab1841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "训练数据集及的长度为: 50000\n",
      "测试数据集及的长度为: 10000\n",
      "------第 1 轮训练开始------\n",
      "训练时间: 3.8432178497314453\n",
      "训练次数: 100, Loss: 2.301461696624756\n",
      "训练时间: 4.9580583572387695\n",
      "训练次数: 200, Loss: 2.2890772819519043\n",
      "训练时间: 6.052404403686523\n",
      "训练次数: 300, Loss: 2.265805721282959\n",
      "训练时间: 7.069671630859375\n",
      "训练次数: 400, Loss: 2.210125684738159\n",
      "训练时间: 8.067373514175415\n",
      "训练次数: 500, Loss: 2.1316375732421875\n",
      "训练时间: 9.118994951248169\n",
      "训练次数: 600, Loss: 2.0457425117492676\n",
      "训练时间: 10.191678524017334\n",
      "训练次数: 700, Loss: 2.000765085220337\n",
      "整体测试集上的loss: 315.400390625\n",
      "整体测试集上的正确率: 0.28450000286102295\n",
      "模型已保存\n",
      "------第 2 轮训练开始------\n",
      "训练时间: 12.443027019500732\n",
      "训练次数: 800, Loss: 1.846737027168274\n",
      "训练时间: 13.443705558776855\n",
      "训练次数: 900, Loss: 1.8030729293823242\n",
      "训练时间: 14.469829320907593\n",
      "训练次数: 1000, Loss: 1.8910515308380127\n",
      "训练时间: 15.478224277496338\n",
      "训练次数: 1100, Loss: 2.0446183681488037\n",
      "训练时间: 16.47923755645752\n",
      "训练次数: 1200, Loss: 1.695770263671875\n",
      "训练时间: 17.4947566986084\n",
      "训练次数: 1300, Loss: 1.6296579837799072\n",
      "训练时间: 18.505624771118164\n",
      "训练次数: 1400, Loss: 1.69970703125\n",
      "训练时间: 19.517302751541138\n",
      "训练次数: 1500, Loss: 1.8145711421966553\n",
      "整体测试集上的loss: 293.984130859375\n",
      "整体测试集上的正确率: 0.3337000012397766\n",
      "模型已保存\n",
      "------第 3 轮训练开始------\n",
      "训练时间: 21.70375370979309\n",
      "训练次数: 1600, Loss: 1.7320324182510376\n",
      "训练时间: 22.74407720565796\n",
      "训练次数: 1700, Loss: 1.6084760427474976\n",
      "训练时间: 23.78735637664795\n",
      "训练次数: 1800, Loss: 1.9673010110855103\n",
      "训练时间: 24.781736612319946\n",
      "训练次数: 1900, Loss: 1.6801261901855469\n",
      "训练时间: 25.794585943222046\n",
      "训练次数: 2000, Loss: 1.9059913158416748\n",
      "训练时间: 26.78673815727234\n",
      "训练次数: 2100, Loss: 1.5152251720428467\n",
      "训练时间: 27.795177698135376\n",
      "训练次数: 2200, Loss: 1.4590290784835815\n",
      "训练时间: 28.802733182907104\n",
      "训练次数: 2300, Loss: 1.803063988685608\n",
      "整体测试集上的loss: 256.93511962890625\n",
      "整体测试集上的正确率: 0.40799999237060547\n",
      "模型已保存\n",
      "------第 4 轮训练开始------\n",
      "训练时间: 30.959717988967896\n",
      "训练次数: 2400, Loss: 1.7529938220977783\n",
      "训练时间: 31.97746229171753\n",
      "训练次数: 2500, Loss: 1.343749761581421\n",
      "训练时间: 33.02717304229736\n",
      "训练次数: 2600, Loss: 1.5776410102844238\n",
      "训练时间: 34.09947395324707\n",
      "训练次数: 2700, Loss: 1.6624767780303955\n",
      "训练时间: 35.15853142738342\n",
      "训练次数: 2800, Loss: 1.465185284614563\n",
      "训练时间: 36.177677392959595\n",
      "训练次数: 2900, Loss: 1.569130778312683\n",
      "训练时间: 37.17814040184021\n",
      "训练次数: 3000, Loss: 1.3604192733764648\n",
      "训练时间: 38.19399929046631\n",
      "训练次数: 3100, Loss: 1.4978886842727661\n",
      "整体测试集上的loss: 249.8309326171875\n",
      "整体测试集上的正确率: 0.421999990940094\n",
      "模型已保存\n",
      "------第 5 轮训练开始------\n",
      "训练时间: 40.363412857055664\n",
      "训练次数: 3200, Loss: 1.3110628128051758\n",
      "训练时间: 41.36121368408203\n",
      "训练次数: 3300, Loss: 1.4762660264968872\n",
      "训练时间: 42.37690448760986\n",
      "训练次数: 3400, Loss: 1.4710924625396729\n",
      "训练时间: 43.38127088546753\n",
      "训练次数: 3500, Loss: 1.5819224119186401\n",
      "训练时间: 44.41005516052246\n",
      "训练次数: 3600, Loss: 1.533852458000183\n",
      "训练时间: 45.473692655563354\n",
      "训练次数: 3700, Loss: 1.33820378780365\n",
      "训练时间: 46.555809020996094\n",
      "训练次数: 3800, Loss: 1.2724535465240479\n",
      "训练时间: 47.57658767700195\n",
      "训练次数: 3900, Loss: 1.4693657159805298\n",
      "整体测试集上的loss: 241.32757568359375\n",
      "整体测试集上的正确率: 0.4412999749183655\n",
      "模型已保存\n",
      "------第 6 轮训练开始------\n",
      "训练时间: 49.759660959243774\n",
      "训练次数: 4000, Loss: 1.3861736059188843\n",
      "训练时间: 50.761112689971924\n",
      "训练次数: 4100, Loss: 1.3989900350570679\n",
      "训练时间: 51.77786350250244\n",
      "训练次数: 4200, Loss: 1.4818885326385498\n",
      "训练时间: 52.793461322784424\n",
      "训练次数: 4300, Loss: 1.1827107667922974\n",
      "训练时间: 53.80439877510071\n",
      "训练次数: 4400, Loss: 1.1714850664138794\n",
      "训练时间: 54.81664061546326\n",
      "训练次数: 4500, Loss: 1.319885015487671\n",
      "训练时间: 55.82861661911011\n",
      "训练次数: 4600, Loss: 1.3829622268676758\n",
      "整体测试集上的loss: 232.53262329101562\n",
      "整体测试集上的正确率: 0.45899999141693115\n",
      "模型已保存\n",
      "------第 7 轮训练开始------\n",
      "训练时间: 58.068180322647095\n",
      "训练次数: 4700, Loss: 1.2922459840774536\n",
      "训练时间: 59.11883902549744\n",
      "训练次数: 4800, Loss: 1.4843310117721558\n",
      "训练时间: 60.128103494644165\n",
      "训练次数: 4900, Loss: 1.3883774280548096\n",
      "训练时间: 61.1269428730011\n",
      "训练次数: 5000, Loss: 1.420742392539978\n",
      "训练时间: 62.1435489654541\n",
      "训练次数: 5100, Loss: 0.9924911856651306\n",
      "训练时间: 63.1442334651947\n",
      "训练次数: 5200, Loss: 1.3221783638000488\n",
      "训练时间: 64.15048670768738\n",
      "训练次数: 5300, Loss: 1.2322255373001099\n",
      "训练时间: 65.1602098941803\n",
      "训练次数: 5400, Loss: 1.3730041980743408\n",
      "整体测试集上的loss: 224.08290100097656\n",
      "整体测试集上的正确率: 0.48319998383522034\n",
      "模型已保存\n",
      "------第 8 轮训练开始------\n",
      "训练时间: 67.34335160255432\n",
      "训练次数: 5500, Loss: 1.1903375387191772\n",
      "训练时间: 68.3765799999237\n",
      "训练次数: 5600, Loss: 1.1836646795272827\n",
      "训练时间: 69.45591568946838\n",
      "训练次数: 5700, Loss: 1.225837230682373\n",
      "训练时间: 70.52333378791809\n",
      "训练次数: 5800, Loss: 1.1904001235961914\n",
      "训练时间: 71.54191637039185\n",
      "训练次数: 5900, Loss: 1.2978302240371704\n",
      "训练时间: 72.55898451805115\n",
      "训练次数: 6000, Loss: 1.5500260591506958\n",
      "训练时间: 73.57207775115967\n",
      "训练次数: 6100, Loss: 1.0780929327011108\n",
      "训练时间: 74.57714605331421\n",
      "训练次数: 6200, Loss: 1.0959246158599854\n",
      "整体测试集上的loss: 212.68829345703125\n",
      "整体测试集上的正确率: 0.5157999992370605\n",
      "模型已保存\n",
      "------第 9 轮训练开始------\n",
      "训练时间: 76.74606704711914\n",
      "训练次数: 6300, Loss: 1.4195688962936401\n",
      "训练时间: 77.75937914848328\n",
      "训练次数: 6400, Loss: 1.1579426527023315\n",
      "训练时间: 78.77534794807434\n",
      "训练次数: 6500, Loss: 1.6015914678573608\n",
      "训练时间: 79.80893778800964\n",
      "训练次数: 6600, Loss: 1.0744038820266724\n",
      "训练时间: 80.8570966720581\n",
      "训练次数: 6700, Loss: 1.0850183963775635\n",
      "训练时间: 81.92280292510986\n",
      "训练次数: 6800, Loss: 1.0786131620407104\n",
      "训练时间: 82.9577374458313\n",
      "训练次数: 6900, Loss: 1.1062180995941162\n",
      "训练时间: 83.94751977920532\n",
      "训练次数: 7000, Loss: 0.9042627215385437\n",
      "整体测试集上的loss: 202.00059509277344\n",
      "整体测试集上的正确率: 0.5421000123023987\n",
      "模型已保存\n",
      "------第 10 轮训练开始------\n",
      "训练时间: 86.1185553073883\n",
      "训练次数: 7100, Loss: 1.2357755899429321\n",
      "训练时间: 87.12595462799072\n",
      "训练次数: 7200, Loss: 1.0066688060760498\n",
      "训练时间: 88.1264111995697\n",
      "训练次数: 7300, Loss: 1.0957345962524414\n",
      "训练时间: 89.14187669754028\n",
      "训练次数: 7400, Loss: 0.7985084056854248\n",
      "训练时间: 90.15941715240479\n",
      "训练次数: 7500, Loss: 1.243635654449463\n",
      "训练时间: 91.17449617385864\n",
      "训练次数: 7600, Loss: 1.240377426147461\n",
      "训练时间: 92.19198417663574\n",
      "训练次数: 7700, Loss: 0.8363233804702759\n",
      "训练时间: 93.23962759971619\n",
      "训练次数: 7800, Loss: 1.2658764123916626\n",
      "整体测试集上的loss: 193.211669921875\n",
      "整体测试集上的正确率: 0.5669999718666077\n",
      "模型已保存\n"
     ]
    }
   ],
   "source": [
    "# 以 CIFAR10 数据集为例，展示一下完整的模型训练套路，完成对数据集的分类问题\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "# 准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(root=\"dataset\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root=\"dataset\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "# 获得数据集的长度 len(), 即length\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "\n",
    "# 格式化字符串, format() 中的数据会替换 {}\n",
    "print(\"训练数据集及的长度为: {}\".format(train_data_size))\n",
    "print(\"测试数据集及的长度为: {}\".format(test_data_size))\n",
    "\n",
    "# 利用DataLoader 来加载数据\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "class Model(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*4*4, 64),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.model(input)\n",
    "        return input\n",
    "\n",
    "model = Model()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()                        # 在 GPU 上进行训练\n",
    "\n",
    "# 创建损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "if torch.cuda.is_available():\n",
    "    loss_fn = loss_fn.cuda()                    # 在 GPU 上进行训练\n",
    "\n",
    "# 优化器\n",
    "learning_rate = 1e-2        # 1e-2 = 1 * (10)^(-2) = 1 / 100 = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# 设置训练网络的一些参数\n",
    "total_train_step = 0                        # 记录训练的次数\n",
    "total_test_step = 0                         # 记录测试的次数\n",
    "epoch = 10                                  # 训练的轮数\n",
    "\n",
    "# 添加tensorboard\n",
    "writer = SummaryWriter(\"logs_train\")\n",
    "start_time = time.time()                    # 开始训练的时间\n",
    "for i in range(epoch):\n",
    "    print(\"------第 {} 轮训练开始------\".format(i+1))\n",
    "\n",
    "    # 训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        if torch.cuda.is_available():\n",
    "            imgs = imgs.cuda()\n",
    "        targets = targets.cuda()            # 在gpu上训练\n",
    "        outputs = model(imgs)               # 将训练的数据放入\n",
    "        loss = loss_fn(outputs, targets)    # 得到损失值\n",
    "\n",
    "        optimizer.zero_grad()               # 优化过程中首先要使用优化器进行梯度清零\n",
    "        loss.backward()                     # 调用得到的损失，利用反向传播，得到每一个参数节点的梯度\n",
    "        optimizer.step()                    # 对参数进行优化\n",
    "        total_train_step += 1               # 上面就是进行了一次训练，训练次数 +1\n",
    "\n",
    "        # 只有训练步骤是100 倍数的时候才打印数据，可以减少一些没有用的数据，方便我们找到其他数据\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time = time.time()          # 训练结束时间\n",
    "            print(\"训练时间: {}\".format(end_time - start_time))\n",
    "            print(\"训练次数: {}, Loss: {}\".format(total_train_step, loss))\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
    "\n",
    "\n",
    "    # 如何知道模型有没有训练好，即有咩有达到自己想要的需求\n",
    "    # 我们可以在每次训练完一轮后，进行一次测试，在测试数据集上跑一遍，以测试数据集上的损失或正确率评估我们的模型有没有训练好\n",
    "\n",
    "    # 顾名思义，下面的代码没有梯度，即我们不会利用进行调优\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0                                      # 准确率\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:                        # 测试数据集中取数据\n",
    "            imgs, targets = data\n",
    "            if torch.cuda.is_available():\n",
    "                imgs = imgs.cuda()                          # 在 GPU 上进行训练\n",
    "                targets = targets.cuda()\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, targets)                # 这里的 loss 只是一部分数据(data) 在网络模型上的损失\n",
    "            total_test_loss = total_test_loss + loss        # 整个测试集的loss\n",
    "            accuracy = (outputs.argmax(1) == targets).sum() # 分类正确个数\n",
    "            total_accuracy += accuracy                      # 相加\n",
    "\n",
    "    print(\"整体测试集上的loss: {}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率: {}\".format(total_accuracy / test_data_size))\n",
    "    writer.add_scalar(\"test_loss\", total_test_loss)\n",
    "    writer.add_scalar(\"test_accuracy\", total_accuracy / test_data_size, total_test_step)\n",
    "    total_test_loss += 1                                    # 测试完了之后要 +1\n",
    "\n",
    "    torch.save(model, \"model_{}.pth\".format(i))\n",
    "    print(\"模型已保存\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea3173a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "训练数据集及的长度为: 50000\n",
      "测试数据集及的长度为: 10000\n",
      "------第 1 轮训练开始------\n",
      "训练时间: 1.2342050075531006\n",
      "训练次数: 100, Loss: 2.282177448272705\n",
      "训练时间: 2.233593225479126\n",
      "训练次数: 200, Loss: 2.2736942768096924\n",
      "训练时间: 3.2655892372131348\n",
      "训练次数: 300, Loss: 2.204333543777466\n",
      "训练时间: 4.284208297729492\n",
      "训练次数: 400, Loss: 2.1174211502075195\n",
      "训练时间: 5.312605857849121\n",
      "训练次数: 500, Loss: 1.9917079210281372\n",
      "训练时间: 6.333043336868286\n",
      "训练次数: 600, Loss: 2.0082876682281494\n",
      "训练时间: 7.33498477935791\n",
      "训练次数: 700, Loss: 1.9690537452697754\n",
      "整体测试集上的loss: 304.3615417480469\n",
      "整体测试集上的正确率: 0.3132999837398529\n",
      "模型已保存\n",
      "------第 2 轮训练开始------\n",
      "训练时间: 9.588040351867676\n",
      "训练次数: 800, Loss: 1.800155520439148\n",
      "训练时间: 10.646360874176025\n",
      "训练次数: 900, Loss: 1.7634451389312744\n",
      "训练时间: 11.692577838897705\n",
      "训练次数: 1000, Loss: 1.868146300315857\n",
      "训练时间: 12.71735143661499\n",
      "训练次数: 1100, Loss: 1.9585095643997192\n",
      "训练时间: 13.73293423652649\n",
      "训练次数: 1200, Loss: 1.6727432012557983\n",
      "训练时间: 14.749567747116089\n",
      "训练次数: 1300, Loss: 1.601604700088501\n",
      "训练时间: 15.767637014389038\n",
      "训练次数: 1400, Loss: 1.6950130462646484\n",
      "训练时间: 16.78651523590088\n",
      "训练次数: 1500, Loss: 1.783077359199524\n",
      "整体测试集上的loss: 294.6297302246094\n",
      "整体测试集上的正确率: 0.32729998230934143\n",
      "模型已保存\n",
      "------第 3 轮训练开始------\n",
      "训练时间: 18.960360288619995\n",
      "训练次数: 1600, Loss: 1.6949467658996582\n",
      "训练时间: 19.982674837112427\n",
      "训练次数: 1700, Loss: 1.6442041397094727\n",
      "训练时间: 21.03184485435486\n",
      "训练次数: 1800, Loss: 1.9627684354782104\n",
      "训练时间: 22.12166738510132\n",
      "训练次数: 1900, Loss: 1.6894912719726562\n",
      "训练时间: 23.18026113510132\n",
      "训练次数: 2000, Loss: 1.9156349897384644\n",
      "训练时间: 24.209668159484863\n",
      "训练次数: 2100, Loss: 1.4817743301391602\n",
      "训练时间: 25.216795206069946\n",
      "训练次数: 2200, Loss: 1.4217422008514404\n",
      "训练时间: 26.23944664001465\n",
      "训练次数: 2300, Loss: 1.774867296218872\n",
      "整体测试集上的loss: 259.506591796875\n",
      "整体测试集上的正确率: 0.40209999680519104\n",
      "模型已保存\n",
      "------第 4 轮训练开始------\n",
      "训练时间: 28.430891513824463\n",
      "训练次数: 2400, Loss: 1.7133958339691162\n",
      "训练时间: 29.4413743019104\n",
      "训练次数: 2500, Loss: 1.3499401807785034\n",
      "训练时间: 30.46662187576294\n",
      "训练次数: 2600, Loss: 1.5599831342697144\n",
      "训练时间: 31.481701135635376\n",
      "训练次数: 2700, Loss: 1.5974712371826172\n",
      "训练时间: 32.546552896499634\n",
      "训练次数: 2800, Loss: 1.4508908987045288\n",
      "训练时间: 33.61243033409119\n",
      "训练次数: 2900, Loss: 1.5838940143585205\n",
      "训练时间: 34.66299557685852\n",
      "训练次数: 3000, Loss: 1.3215540647506714\n",
      "训练时间: 35.68245053291321\n",
      "训练次数: 3100, Loss: 1.5394316911697388\n",
      "整体测试集上的loss: 250.8511505126953\n",
      "整体测试集上的正确率: 0.4220999777317047\n",
      "模型已保存\n",
      "------第 5 轮训练开始------\n",
      "训练时间: 37.852221727371216\n",
      "训练次数: 3200, Loss: 1.3443822860717773\n",
      "训练时间: 38.88035440444946\n",
      "训练次数: 3300, Loss: 1.470581293106079\n",
      "训练时间: 39.89899039268494\n",
      "训练次数: 3400, Loss: 1.4522960186004639\n",
      "训练时间: 40.91520118713379\n",
      "训练次数: 3500, Loss: 1.5386189222335815\n",
      "训练时间: 41.94907236099243\n",
      "训练次数: 3600, Loss: 1.5443247556686401\n",
      "训练时间: 42.9502477645874\n",
      "训练次数: 3700, Loss: 1.3109567165374756\n",
      "训练时间: 43.98027324676514\n",
      "训练次数: 3800, Loss: 1.2420724630355835\n",
      "训练时间: 45.03012490272522\n",
      "训练次数: 3900, Loss: 1.446702480316162\n",
      "整体测试集上的loss: 243.95851135253906\n",
      "整体测试集上的正确率: 0.4406999945640564\n",
      "模型已保存\n",
      "------第 6 轮训练开始------\n",
      "训练时间: 47.289684772491455\n",
      "训练次数: 4000, Loss: 1.3720684051513672\n",
      "训练时间: 48.31569290161133\n",
      "训练次数: 4100, Loss: 1.3944863080978394\n",
      "训练时间: 49.31603479385376\n",
      "训练次数: 4200, Loss: 1.5665667057037354\n",
      "训练时间: 50.332834243774414\n",
      "训练次数: 4300, Loss: 1.2465026378631592\n",
      "训练时间: 51.36353158950806\n",
      "训练次数: 4400, Loss: 1.1347044706344604\n",
      "训练时间: 52.38576340675354\n",
      "训练次数: 4500, Loss: 1.3398096561431885\n",
      "训练时间: 53.41359210014343\n",
      "训练次数: 4600, Loss: 1.4037501811981201\n",
      "整体测试集上的loss: 236.54652404785156\n",
      "整体测试集上的正确率: 0.45319998264312744\n",
      "模型已保存\n",
      "------第 7 轮训练开始------\n",
      "训练时间: 55.634814977645874\n",
      "训练次数: 4700, Loss: 1.3422297239303589\n",
      "训练时间: 56.7071967124939\n",
      "训练次数: 4800, Loss: 1.5121207237243652\n",
      "训练时间: 57.7490394115448\n",
      "训练次数: 4900, Loss: 1.3713576793670654\n",
      "训练时间: 58.77946400642395\n",
      "训练次数: 5000, Loss: 1.4102802276611328\n",
      "训练时间: 59.797868490219116\n",
      "训练次数: 5100, Loss: 0.9714681506156921\n",
      "训练时间: 60.81471824645996\n",
      "训练次数: 5200, Loss: 1.3148871660232544\n",
      "训练时间: 61.83181428909302\n",
      "训练次数: 5300, Loss: 1.1442818641662598\n",
      "训练时间: 62.84730553627014\n",
      "训练次数: 5400, Loss: 1.3549731969833374\n",
      "整体测试集上的loss: 227.56361389160156\n",
      "整体测试集上的正确率: 0.4802999794483185\n",
      "模型已保存\n",
      "------第 8 轮训练开始------\n",
      "训练时间: 65.03113842010498\n",
      "训练次数: 5500, Loss: 1.1761003732681274\n",
      "训练时间: 66.06285262107849\n",
      "训练次数: 5600, Loss: 1.20895254611969\n",
      "训练时间: 67.09615206718445\n",
      "训练次数: 5700, Loss: 1.1932073831558228\n",
      "训练时间: 68.17649054527283\n",
      "训练次数: 5800, Loss: 1.2102240324020386\n",
      "训练时间: 69.24378180503845\n",
      "训练次数: 5900, Loss: 1.3154195547103882\n",
      "训练时间: 70.26499342918396\n",
      "训练次数: 6000, Loss: 1.5716572999954224\n",
      "训练时间: 71.3020830154419\n",
      "训练次数: 6100, Loss: 1.0166248083114624\n",
      "训练时间: 72.32939195632935\n",
      "训练次数: 6200, Loss: 1.1128246784210205\n",
      "整体测试集上的loss: 219.5138397216797\n",
      "整体测试集上的正确率: 0.4992999732494354\n",
      "模型已保存\n",
      "------第 9 轮训练开始------\n",
      "训练时间: 74.54962134361267\n",
      "训练次数: 6300, Loss: 1.4163509607315063\n",
      "训练时间: 75.5799343585968\n",
      "训练次数: 6400, Loss: 1.115729808807373\n",
      "训练时间: 76.59823107719421\n",
      "训练次数: 6500, Loss: 1.5667260885238647\n",
      "训练时间: 77.62930750846863\n",
      "训练次数: 6600, Loss: 1.0747328996658325\n",
      "训练时间: 78.63152122497559\n",
      "训练次数: 6700, Loss: 1.0520116090774536\n",
      "训练时间: 79.69451761245728\n",
      "训练次数: 6800, Loss: 1.1511703729629517\n",
      "训练时间: 80.74544882774353\n",
      "训练次数: 6900, Loss: 1.065644383430481\n",
      "训练时间: 81.80206942558289\n",
      "训练次数: 7000, Loss: 0.8908315896987915\n",
      "整体测试集上的loss: 209.80027770996094\n",
      "整体测试集上的正确率: 0.5242999792098999\n",
      "模型已保存\n",
      "------第 10 轮训练开始------\n",
      "训练时间: 83.98902082443237\n",
      "训练次数: 7100, Loss: 1.2302114963531494\n",
      "训练时间: 85.01491498947144\n",
      "训练次数: 7200, Loss: 0.9891238808631897\n",
      "训练时间: 86.02946043014526\n",
      "训练次数: 7300, Loss: 1.1477301120758057\n",
      "训练时间: 87.06378149986267\n",
      "训练次数: 7400, Loss: 0.8351137042045593\n",
      "训练时间: 88.08039283752441\n",
      "训练次数: 7500, Loss: 1.2013081312179565\n",
      "训练时间: 89.09719252586365\n",
      "训练次数: 7600, Loss: 1.2752724885940552\n",
      "训练时间: 90.12855839729309\n",
      "训练次数: 7700, Loss: 0.8725579380989075\n",
      "训练时间: 91.19240498542786\n",
      "训练次数: 7800, Loss: 1.32646644115448\n",
      "整体测试集上的loss: 202.26715087890625\n",
      "整体测试集上的正确率: 0.5421000123023987\n",
      "模型已保存\n"
     ]
    }
   ],
   "source": [
    "# 以 CIFAR10 数据集为例，展示一下完整的模型训练套路，完成对数据集的分类问题\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "# 定义训练的设备\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# 准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(root=\"dataset\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root=\"dataset\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "# 获得数据集的长度 len(), 即length\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "\n",
    "# 格式化字符串, format() 中的数据会替换 {}\n",
    "print(\"训练数据集及的长度为: {}\".format(train_data_size))\n",
    "print(\"测试数据集及的长度为: {}\".format(test_data_size))\n",
    "\n",
    "# 利用DataLoader 来加载数据\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "class Model(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*4*4, 64),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.model(input)\n",
    "        return input\n",
    "\n",
    "model = Model()\n",
    "model = model.to(device)                    # 在 GPU 上进行训练\n",
    "\n",
    "# 创建损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)                # 在 GPU 上进行训练\n",
    "\n",
    "# 优化器\n",
    "learning_rate = 1e-2        # 1e-2 = 1 * (10)^(-2) = 1 / 100 = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# 设置训练网络的一些参数\n",
    "total_train_step = 0                        # 记录训练的次数\n",
    "total_test_step = 0                         # 记录测试的次数\n",
    "epoch = 10                                  # 训练的轮数\n",
    "\n",
    "# 添加tensorboard\n",
    "writer = SummaryWriter(\"logs_train\")\n",
    "start_time = time.time()                    # 开始训练的时间\n",
    "for i in range(epoch):\n",
    "    print(\"------第 {} 轮训练开始------\".format(i+1))\n",
    "\n",
    "    # 训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(imgs)               # 将训练的数据放入\n",
    "        loss = loss_fn(outputs, targets)    # 得到损失值\n",
    "\n",
    "        optimizer.zero_grad()               # 优化过程中首先要使用优化器进行梯度清零\n",
    "        loss.backward()                     # 调用得到的损失，利用反向传播，得到每一个参数节点的梯度\n",
    "        optimizer.step()                    # 对参数进行优化\n",
    "        total_train_step += 1               # 上面就是进行了一次训练，训练次数 +1\n",
    "\n",
    "        # 只有训练步骤是100 倍数的时候才打印数据，可以减少一些没有用的数据，方便我们找到其他数据\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time = time.time()          # 训练结束时间\n",
    "            print(\"训练时间: {}\".format(end_time - start_time))\n",
    "            print(\"训练次数: {}, Loss: {}\".format(total_train_step, loss))\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
    "\n",
    "\n",
    "    # 如何知道模型有没有训练好，即有咩有达到自己想要的需求\n",
    "    # 我们可以在每次训练完一轮后，进行一次测试，在测试数据集上跑一遍，以测试数据集上的损失或正确率评估我们的模型有没有训练好\n",
    "\n",
    "    # 顾名思义，下面的代码没有梯度，即我们不会利用进行调优\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0                                      # 准确率\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:                        # 测试数据集中取数据\n",
    "            imgs, targets = data\n",
    "            imgs = imgs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, targets)                # 这里的 loss 只是一部分数据(data) 在网络模型上的损失\n",
    "            total_test_loss = total_test_loss + loss        # 整个测试集的loss\n",
    "            accuracy = (outputs.argmax(1) == targets).sum() # 分类正确个数\n",
    "            total_accuracy += accuracy                      # 相加\n",
    "\n",
    "    print(\"整体测试集上的loss: {}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率: {}\".format(total_accuracy / test_data_size))\n",
    "    writer.add_scalar(\"test_loss\", total_test_loss)\n",
    "    writer.add_scalar(\"test_accuracy\", total_accuracy / test_data_size, total_test_step)\n",
    "    total_test_loss += 1                                    # 测试完了之后要 +1\n",
    "\n",
    "    torch.save(model, \"model_{}.pth\".format(i))\n",
    "    print(\"模型已保存\")\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b43a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
